{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify if question is relevant to be stored in Long-Term-Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeQuestion(BaseModel):\n",
    "    \"\"\"Boolean value to check whether a question is related to the specified topics.\"\"\"\n",
    "\n",
    "    score: str = Field(\n",
    "        description=\"Is the question relevant? Respond with 'Yes' or 'No'.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"\n",
    "You are a classifier that examines the given question or statement for any personal information or preferences.\n",
    "Your job is to determine whether the input contains:\n",
    "1. Personal information about the user (e.g., name, occupation, location, contact details, or other identifiable information).\n",
    "2. Preferences, habits, or any explicitly mentioned likes/dislikes.\n",
    "\n",
    "If you find any such information, respond with 'Yes'. If the input does not contain any personal information or preferences, respond with 'No'.\n",
    "Your response must be ONLY 'Yes' or 'No'.\n",
    "\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Here is the input: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "structured_llm = llm.with_structured_output(GradeQuestion)\n",
    "grader_llm = grade_prompt | structured_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeQuestion(score='No')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader_llm.invoke({\"question\": \"Where is Thomas M端ller from?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeQuestion(score='Yes')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader_llm.invoke({\"question\": \"Where is Thomas M端ller from? I love playing football myself\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise question/information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Where is Thomas M端ller from? I love playing football myself.\"\n",
    "\n",
    "system = \"\"\"\n",
    "You are an extractor focused on identifying and summarizing personal information from the given input.\n",
    "Personal information includes:\n",
    "1. Names of individuals.\n",
    "2. Locations.\n",
    "3. Hobbies, preferences, or habits explicitly mentioned by the user.\n",
    "4. Any other identifiable personal details.\n",
    "\n",
    "Your task is to:\n",
    "- Extract only the personal information present in the input.\n",
    "- Ignore any irrelevant or general information.\n",
    "- Provide the extracted personal information as a concise, single-sentence summary.\n",
    "\n",
    "If no personal information is found, respond with 'No personal information found.'\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", f\"Extract and summarize personal information: {message}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "summarizer = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Personal Information: content='Thomas M端ller is mentioned, and the user loves playing football.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 138, 'total_tokens': 151, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None} id='run-fb0cacde-d003-4bf8-b6b6-4be1727217ae-0' usage_metadata={'input_tokens': 138, 'output_tokens': 13, 'total_tokens': 151, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the summarizer and print the result\n",
    "result = summarizer.invoke({})\n",
    "print(f\"Extracted Personal Information: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
